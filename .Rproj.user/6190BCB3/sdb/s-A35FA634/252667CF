{
    "collab_server" : "",
    "contents" : "library(rvest)\nlibrary(xml2)\nlibrary(stringr)\noptions(warn=-1)\n\n# where to save the downloads, this is the only thing to set up\nworking_directory=\"C:/Users/weny/Google Drive/2018/Humanitarian/MISP/MISP-Rproject/\"\n\n# define a function that 'clean country name'(ccn), e.g. ccn(\"CÃ´te d'Ivoire\")='Cote d Ivoire'\nccn=function(string){\n  # remove non-alphabetic\n  string=str_replace_all(string, \"[[:punct:]]\", \" \")\n  # remove Latin letters\n  return(iconv(string,from=\"UTF-8\", to='ASCII//TRANSLIT'))}\n\n# build a country list from https://www.unfpa.org/worldwide\ncountry_list=c('Angola','Botswana','Burundi','Comoros','Democratic Republic of the Congo',\n               'Eritrea','Eswatini','Ethiopia','Kenya','Lesotho','Madagascar','Malawi','Mozambique',\n               'Namibia','Rwanda','Seychelles','South Africa','South Sudan',\n               'United Republic of Tanzania','Uganda','Zambia','Zimbabwe','Benin','Burkina Faso',\n               'Republic of Cameroon','Cabo Verde','Central African Republic','Chad',\n               'Republic of Congo','Cote d Ivoire','Equatorial Guinea','Gabon','Gambia','Ghana',\n               'Guinea','Guinea-Bissau','Liberia','Mali','Mauritania','Niger','Nigeria',\n               'Sao Tome and Principe','Senegal','Sierra Leone','Togo','Algeria','Djibouti',\n               'Egypt','Kingdom of Bahrain','Kingdom of Saudi Arabia','State of Kuwait',\n               'State of Qatar','United Arab Emirates','Sultanate of Oman','Iraq','Jordan','Lebanon',\n               'Libyan Arab Jamahiriya','Morocco','State of Palestine','Somalia','Sudan',\n               'Syrian Arab Republic','Tunisia','Yemen','Afghanistan','Bangladesh','Bhutan',\n               'Cambodia','China','Democratic Peoples Republic of Korea','India','Indonesia',\n               'Islamic Republic of Iran','Lao People s Democratic Republic','Malaysia','Maldives',\n               'Mongolia','Myanmar','Nepal','Cook Islands','Federated States of Micronesia',\n               'Fiji','Kiribati','Marshall Islands','Nauru','Niue','Palau','Samoa',\n               'Solomon Islands','Tokelau','Tonga','Tuvalu and Vanuatu','Pakistan',\n               'Papua New Guinea','Philippines','Sri Lanka','Thailand','Timor-Leste','Viet Nam',\n               'Albania','Armenia','Azerbaijan','Belarus','Bosnia & Herzegovina','Georgia',\n               'Kazakhstan','Kosovo','Kyrgyzstan','Macedonia','Moldova','Serbia','Tajikistan',\n               'Turkey','Turkmenistan','Ukraine','Uzbekistan','Argentina','Bolivia','Brazil',\n               ' Belize','Guyana','Saint Lucia','Jamaica','Suriname','Trinidad and Tobago',\n               'Anguilla','Antigua and Barbuda','Aruba','Bahamas','Barbados','Bermuda',\n               'British Virgin Islands','Cayman Islands','Dominica','Grenada','Montserrat',\n               'Netherlands Antilles','Saint Kitts and Nevis','Saint Vincent and the Grenadines',\n               'Turks and Caicos Islands','Chile','Colombia','Costa Rica','Cuba',\n               'Dominican Republic','Ecuador','El Salvador','Guatemala','Haiti','Honduras','Mexico',\n               'Nicaragua','Panama','Paraguay','Peru','Uruguay','Venezuela')\n\n\n###### current criteria: subnational and contains 'population', format (csv),xls,xlsx\nstart_time = Sys.time()\n#initializing\npagenumber=1\npage_empty=0\nall_desc=c()\nall_address=c()\nall_location=c()\nall_date=c()\nall_local_address=c()\nwhat=0\n\nwhile (page_empty==0){\n  # for each page in main website\n  prefix=\"https://data.humdata.org/dataset?ext_subnational=1&res_format=XLS&res_format=XLSX&tags=population&page=\"\n  #################\n  # &res_format=CSV [NOT SUPPORTED YET BECAUSE OF JUDGE_EACH_DT]\n  #################\n  # read current page as html format\n  main=read_html(paste0(prefix,pagenumber))\n  # find its nodes (subpages)\n  scrape0 <- html_nodes(main,xpath=\".//*[contains(@class,'dataset-heading')]//a\")\n  \n  # store the url connecting the subpage\n  address0=html_attr(scrape0,'href')\n  \n  # determine whether we have reached the last page\n  page_empty=1-sign(length(address0))\n  pagenumber=pagenumber+1\n  \n  # break if empty\n  if (page_empty==1){break}\n  \n  \n  # extract details like location and year, for all subpages of current page\n\n  for (i in 1:length(address0)){\n    \n    # read html of subpage\n    subpage <- read_html(paste0(\"https://data.humdata.org\",address0[i]))\n    \n    # scrape the website for description, data, date and location\n    desc = html_nodes(subpage,xpath=\".//*[contains(@class,'itemTitle')]\")\n    data = html_nodes(subpage,xpath=\".//*[contains(@class,'resource-icon-btn')]\")\n    loca = html_nodes(subpage,xpath=\".//*[contains(@class,'mx-country')]//a\")\n    year = html_nodes(subpage,xpath=\".//tr[(((count(preceding-sibling::*) + 1) = 3) and parent::*)]//*[contains(@class,'dataset-details')]\")\n    \n    # there is one case where date is missing!\n    # https://data.humdata.org/dataset/proyecciones-de-poblacion-municipalmente\n    # there are also multiple cases where location is not unique, we ignore this\n    # https://data.humdata.org/dataset/lcb-displaced\n    if (length(html_text(desc))>0 && length(html_text(loca))==1){\n      \n      address=html_attr(data,'href')\n      \n      # extend url link to full address\n      addr=paste0('https://data.humdata.org',address)\n      \n      # extract the file style if '.' exists\n      if (grepl('[.]',address)){\n        style=tail(strsplit(address,'[.]')[[1]],1)\n        # examine whether style is (csv),xls,xlsx (prefix criterion is not accurate)\n        if (style=='xls' || style=='xlsx'){\n          loc=ccn(html_text(loca))\n          # examine whether location is in country list\n          if (!loc %in% country_list){\n            print(loc)\n          } else{\n            # there are two unusual cases: no date or has a period instead of single date\n            date=html_text(year)\n            \n            if (nchar(date)>=12){\n              clean_date=str_sub(date,-12)\n              all_date = c(all_date,clean_date)\n              all_location = c(all_location,loc)\n              all_desc = c(all_desc,html_text(desc))\n              all_address=c(all_address,paste0(\"https://data.humdata.org\",address0[i]))\n              address_curr=paste0(working_directory,'data/',loc,'_',clean_date,'.',style)\n              all_local_address=c(all_local_address,address_curr)\n              download.file(addr,quiet = 1,destfile = address_curr,mode = \"wb\")\n            }\n          }\n        }\n      }\n    }\n  }\n}\nprint(paste0('COD data processing takes ',round(Sys.time()-start_time,2),' minutes'))\n\n\n# the details of all data downloaded are recorded in a dataframe; \n# this directory has repeated country names; \n# refer to directory variable 'directory_unique' to see which country is done\ndirectory=data.frame(country=all_location,year=all_date,decription=all_desc,link=all_address,location=all_local_address,stringsAsFactors=FALSE)\n\n############ find country unique to most recent date\nas_date=function(string){\n  # we assume the date is like Sep 01,2011\n  temp=strsplit(string,',| ')[[1]]\n  year=temp[4]\n  day=temp[2]pdb.Office-2018\n  month=match(temp[1],c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'))\n  return(as.POSIXct(paste0(year,'/',month,'/',day)))\n}\n\nunique_row=c()\nunique_country=c()\nunique_date=c()\nfor (i in 1:dim(directory)[1]){\n  if (!directory[i,'country'] %in% unique_country){\n    unique_row=c(unique_row,i)\n    unique_country=c(unique_country,directory[i,'country'])\n    unique_date=c(unique_date,as.character(as_date(directory[i,'year'])))\n    print(as_date(directory[i,'year']))\n  } else{\n    # compare which date is more recent, replace if necessary\n    temp_index=match(directory[i,'country'],unique_country)\n    included_date=unique_date[temp_index]\n    to_compare_date=as.character(as_date(directory[i,'year']))\n    if (to_compare_date>included_date){\n      unique_row[temp_index]=i\n      unique_country[temp_index]=directory[i,'country']\n      unique_date[temp_index]=to_compare_date\n    }\n  }\n}\n\n# dataframe records which country is under consideration for info extraction\ndirectory_unique=directory[unique_row,]\n\n################### start to extract disaggregation from highest admin level\nlibrary(readxl)\n\n# define a function that return the index in a list where all strings in first statement can be found\nfind_index=function(str_vec,list_to_look){\n  for (j in 1:length(list_to_look)){\n    all_str_found=1\n    for (i in 1:length(str_vec)){\n      all_str_found=grepl(str_vec[i],list_to_look[j],ignore.case = TRUE)\n      if(all_str_found==0){break}\n    }\n    if (all_str_found==1){return(j)}\n  }\n  return(0)}\n\n\n\n##### evaluate level 2, if not qualified, go to level 1\nextract_level2=function(data2,contain_2){\n  # create an abbreviation\n  col2=colnames(data2)\n  \n  if (find_index(c('male',4),col2)!=0 & find_index(c('female',4),col2)!=0){\n    # c('male','4') finds a column name that contains male and 4-yr old, i.e. both sex/age disaggregation\n    \n    # extract each column\n    admin1_name=find_index(c('Admin1','name'),col2)\n    admin2_name=find_index(c('Admin2','name'),col2)\n    male=find_index(c('Male'),col2)\n    female=find_index(c('Female'),col2)\n    m_age0_4=find_index(c('male','4'),col2)\n    m_age5_9=find_index(c('male','5','9'),col2)\n    m_age10_14=find_index(c('male','10','14'),col2)\n    m_age15_19=find_index(c('male','15','19'),col2)\n    m_age20_24=find_index(c('male','20','24'),col2)\n    m_age25_29=find_index(c('male','25','29'),col2)\n    m_age30_34=find_index(c('male','30','34'),col2)\n    m_age35_39=find_index(c('male','35','39'),col2)\n    m_age40_44=find_index(c('male','40','44'),col2)\n    m_age45_49=find_index(c('male','45','49'),col2)\n    m_age50_54=find_index(c('male','50','54'),col2)\n    m_age55_59=find_index(c('male','55','59'),col2)\n    m_age60_64=find_index(c('male','60','64'),col2)\n    m_age65_69=find_index(c('male','65','69'),col2)\n    m_age70_74=find_index(c('male','70','74'),col2)\n    m_age75_79=find_index(c('male','75','79'),col2)\n    m_age80_=find_index(c('male','80'),col2)\n    \n    f_age0_4=find_index(c('female','4'),col2)\n    f_age5_9=find_index(c('female','5','9'),col2)\n    f_age10_14=find_index(c('female','10','14'),col2)\n    f_age15_19=find_index(c('female','15','19'),col2)\n    f_age20_24=find_index(c('female','20','24'),col2)\n    f_age25_29=find_index(c('female','25','29'),col2)\n    f_age30_34=find_index(c('female','30','34'),col2)\n    f_age35_39=find_index(c('female','35','39'),col2)\n    f_age40_44=find_index(c('female','40','44'),col2)\n    f_age45_49=find_index(c('female','45','49'),col2)\n    f_age50_54=find_index(c('female','50','54'),col2)\n    f_age55_59=find_index(c('female','55','59'),col2)\n    f_age60_64=find_index(c('female','60','64'),col2)\n    f_age65_69=find_index(c('female','65','69'),col2)\n    f_age70_74=find_index(c('female','70','74'),col2)\n    f_age75_79=find_index(c('female','75','79'),col2)\n    f_age80_=find_index(c('female','80'),col2)\n    \n    # compile into a new dataframe\n    extracted=data2[,c(admin1_name,admin2_name,male,female,m_age0_4,m_age5_9,m_age10_14,m_age15_19,\n                       m_age20_24,m_age25_29,m_age30_34,m_age35_39,m_age40_44,m_age45_49,m_age50_54,\n                       m_age55_59,m_age60_64,m_age65_69,m_age70_74,m_age75_79,m_age80_,\n                       f_age0_4,f_age5_9,f_age10_14,f_age15_19,f_age20_24,f_age25_29,f_age30_34,\n                       f_age35_39,f_age40_44,f_age45_49,f_age50_54,f_age55_59,f_age60_64,\n                       f_age65_69,f_age70_74,f_age75_79,f_age80_)]\n    colnames(extracted)=c('Admin1','Admin2','Male','Female','male 0-4','male 5-9','male 10-14',\n                          'male 15-19','male 20-24','male 25-29','male 30-34','male 35-39',\n                          'male 40-44','male 45-49','male 50-54','male 55-59','male 60-64',\n                          'male 65-69','male 70-74','male 75-79','male 80+','female 0-4',\n                          'female 5-9','female 10-14','female 15-19','female 20-24',\n                          'female 25-29','female 30-34','female 35-39','female 40-44',\n                          'female 45-49','female 50-54','female 55-59','female 60-64',\n                          'female 65-69','female 70-74','female 75-79','female 80+')\n    \n    return(list(extracted,contain_2))\n  }else{\n    # if admin level 2 does not qualify, indicate this by making contain_2=0\n    contain_2=0\n    print('This data has level 2 data but not about sex AND age disaggregation')\n    return(list(data2,contain_2))\n  }}\n\n##### evaluate level 1\nextract_level1=function(data1,contain_1){\n  # create an abbreviation\n  col1=colnames(data1)\n  \n  if (find_index(c('male',4),col1)!=0 & find_index(c('female',4),col1)!=0){\n    \n    admin1_name=find_index(c('Admin1','name'),col1)\n    male=find_index(c('Male'),col1)\n    female=find_index(c('Female'),col1)\n    m_age0_4=find_index(c('male','4'),col1)\n    m_age5_9=find_index(c('male','5','9'),col1)\n    m_age10_14=find_index(c('male','10','14'),col1)\n    m_age15_19=find_index(c('male','15','19'),col1)\n    m_age20_24=find_index(c('male','20','24'),col1)\n    m_age25_29=find_index(c('male','25','29'),col1)\n    m_age30_34=find_index(c('male','30','34'),col1)\n    m_age35_39=find_index(c('male','35','39'),col1)\n    m_age40_44=find_index(c('male','40','44'),col1)\n    m_age45_49=find_index(c('male','45','49'),col1)\n    m_age50_54=find_index(c('male','50','54'),col1)\n    m_age55_59=find_index(c('male','55','59'),col1)\n    m_age60_64=find_index(c('male','60','64'),col1)\n    m_age65_69=find_index(c('male','65','69'),col1)\n    m_age70_74=find_index(c('male','70','74'),col1)\n    m_age75_79=find_index(c('male','75','79'),col1)\n    m_age80_84=find_index(c('male','80','84'),col1)\n    m_age85_89=find_index(c('male','85','89'),col1)\n    m_age90_94=find_index(c('male','90','94'),col1)\n    m_age95_99=find_index(c('male','95','99'),col1)\n    m_age100_=find_index(c('male','100'),col1)\n    f_age0_4=find_index(c('female','4'),col1)\n    f_age5_9=find_index(c('female','5','9'),col1)\n    f_age10_14=find_index(c('female','10','14'),col1)\n    f_age15_19=find_index(c('female','15','19'),col1)\n    f_age20_24=find_index(c('female','20','24'),col1)\n    f_age25_29=find_index(c('female','25','29'),col1)\n    f_age30_34=find_index(c('female','30','34'),col1)\n    f_age35_39=find_index(c('female','35','39'),col1)\n    f_age40_44=find_index(c('female','40','44'),col1)\n    f_age45_49=find_index(c('female','45','49'),col1)\n    f_age50_54=find_index(c('female','50','54'),col1)\n    f_age55_59=find_index(c('female','55','59'),col1)\n    f_age60_64=find_index(c('female','60','64'),col1)\n    f_age65_69=find_index(c('female','65','69'),col1)\n    f_age70_74=find_index(c('female','70','74'),col1)\n    f_age75_79=find_index(c('female','75','79'),col1)\n    f_age80_84=find_index(c('female','80','84'),col1)\n    f_age85_89=find_index(c('female','85','89'),col1)\n    f_age90_94=find_index(c('female','90','94'),col1)\n    f_age95_99=find_index(c('female','95','99'),col1)\n    f_age100_=find_index(c('female','100'),col1)\n    \n    \n    extracted=data1[,c(admin1_name,male,female,m_age0_4,m_age5_9,m_age10_14,m_age15_19,m_age20_24,\n                       m_age25_29,m_age30_34,m_age35_39,m_age40_44,m_age45_49,m_age50_54,\n                       m_age55_59,m_age60_64,m_age65_69,m_age70_74,m_age75_79,m_age80_84,\n                       m_age85_89,m_age90_94,m_age95_99,m_age100_,f_age0_4,f_age5_9,\n                       f_age10_14,f_age15_19,f_age20_24,f_age25_29,f_age30_34,f_age35_39,\n                       f_age40_44,f_age45_49,f_age50_54,f_age55_59,f_age60_64,f_age65_69,\n                       f_age70_74,f_age75_79,f_age80_84,f_age85_89,f_age90_94,f_age95_99,f_age100_)]\n    max_length_str=c('Admin1','Male','Female','male 0-4','male 5-9','male 10-14','male 15-19',\n                     'male 20-24','male 25-29','male 30-34','male 35-39','male 40-44',\n                     'male 45-49','male 50-54','male 55-59','male 60-64','male 65-69',\n                     'male 70-74','male 75-79','male 80-84','male 85-89','male 90-94',\n                     'male 95-99','male 100+','female 0-4','female 5-9','female 10-14',\n                     'female 15-19','female 20-24','female 25-29','female 30-34',\n                     'female 35-39','female 40-44','female 45-49','female 50-54',\n                     'female 55-59','female 60-64','female 65-69','female 70-74',\n                     'female 75-79','female 80-84','female 85-89','female 90-94',\n                     'female 95-99','female 100+')\n    colnames(extracted)=max_length_str[1:dim(extracted)[2]]\n    \n    return(list(extracted,contain_1))\n  }else{\n    contain_1=0\n    print('This data has level 1 data but not about sex')\n    return(list(data1,contain_1))\n  }}\n\n# follow the decision tree in 'summary of HDX collector.pptx'\njudge_each_DT=function(address){\n  sheet_names=excel_sheets(address)\n  \n  contain_1=0\n  contain_2=0\n  \n  contain_1=find_index(c('a','min','1'),sheet_names)\n  if (contain_1!=0){data1=read_excel(address,sheet=contain_1)\n  }else{data1=0;print('This country doesnt have level 1 data')}\n  \n  contain_2=find_index(c('a','min','2'),sheet_names)\n  if (contain_2!=0){data2=read_excel(address,sheet=contain_2)\n  }else{data2=0;print('This country doesnt have level 2 data')}\n  \n  if (contain_2!=0){\n    answer2=extract_level2(data2,contain_2)\n    contain_2=answer2[[2]]\n    extracted=answer2[[1]]\n  }\n  \n  if(contain_2!=0){\n    print('This data HAS LEVEL 2 sex/age data')\n    return(extracted)}\n  \n  ###\n  if (contain_1!=0){\n    answer1=extract_level1(data1,contain_1)\n    contain_1=answer1[[2]]\n    extracted=answer1[[1]]\n  }\n  \n  if(contain_1!=0){\n    print('This data HAS LEVEL 1 sex/age data')\n    return(extracted)}\n  \n  return('This data has no disaggregated data')\n}\n\n\n\n############ save all uniformly-format data in a folder 'uniform'\n# create a list that record all countries finished at current stage\nfinal_list=c()\nfor (i in 1:dim(directory_unique)[1]){\n  print(paste0('processing',directory_unique[i,'location']))\n  answer=judge_each_DT(directory_unique[i,'location'])\n  if (class(answer)!='character'){\n  write.csv(answer,paste0(working_directory,'uniform/',directory_unique[i,'country'],\n                          '_',directory_unique[i,'year'],'.csv'))\n  # record all true valid country in a dataframe\n  final_list=c(final_list,directory_unique[i,'country'])\n  }\n}\n\n\n",
    "created" : 1535479020749.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1003516069",
    "id" : "252667CF",
    "lastKnownWriteTime" : 1535492081,
    "last_content_update" : 1535492081362,
    "path" : "C:/Users/weny/Google Drive/2018/Humanitarian/MISP/MISP-Rproject/COD collector.R",
    "project_path" : "COD collector.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}